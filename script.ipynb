{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images shape:  (138, 400, 400, 4)\n",
      "poses shape:  (138, 4, 4)\n",
      "[[-9.9990219e-01  4.1922452e-03 -1.3345719e-02 -5.3798322e-02]\n",
      " [-1.3988681e-02 -2.9965907e-01  9.5394367e-01  3.8454704e+00]\n",
      " [-4.6566129e-10  9.5403719e-01  2.9968831e-01  1.2080823e+00]\n",
      " [ 0.0000000e+00  0.0000000e+00  0.0000000e+00  1.0000000e+00]]\n",
      "i_split: train val test\n",
      "hwf:  [400, 400, 555.5555155968841]\n",
      "render poses:  torch.Size([40, 4, 4])\n",
      "c2w:  torch.Size([4, 4])\n",
      "tensor([[ 1.0000e+00,  6.1232e-17, -1.0606e-16, -4.2423e-16],\n",
      "        [-1.2246e-16,  5.0000e-01, -8.6603e-01, -3.4641e+00],\n",
      "        [ 0.0000e+00,  8.6603e-01,  5.0000e-01,  2.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]])\n"
     ]
    }
   ],
   "source": [
    "from load_blender import load_blender_data\n",
    "basedir = r'./logs'\n",
    "datadir = r'./data/nerf_synthetic/lego'\n",
    "dataset_type = 'blender'\n",
    "\n",
    "no_batching = True\n",
    "\n",
    "use_viewdirs = True\n",
    "white_bkgd = True\n",
    "lrate_decay = 500\n",
    "\n",
    "N_samples = 64\n",
    "N_importance = 128\n",
    "N_rand = 1024\n",
    "\n",
    "precrop_iters = 500\n",
    "precrop_frac = 0.5\n",
    "\n",
    "half_res = True\n",
    "testskip = 8\n",
    "\n",
    "images, poses, render_poses, hwf, i_split = load_blender_data(datadir, half_res, testskip)\n",
    "print('images shape: ', images.shape)\n",
    "print('poses shape: ', poses.shape)\n",
    "print(poses[0])\n",
    "print('i_split: train val test')\n",
    "print('hwf: ', hwf)\n",
    "print('render poses: ', render_poses.shape)\n",
    "print('c2w: ', render_poses[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([400, 400, 3])\n",
      "tensor([-0.3600,  0.3600, -1.0000])\n",
      "torch.Size([400, 400, 3])\n",
      "torch.Size([400, 400, 3])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "# c2w rays_o rays_d\n",
    "H = 400\n",
    "W = 400\n",
    "focal = 555.5555155968841\n",
    "c2w = torch.as_tensor([[1.0000e+00,  6.1232e-17, -1.0606e-16, -4.2423e-16],\n",
    "        [-1.2246e-16,  5.0000e-01, -8.6603e-01, -3.4641e+00],\n",
    "        [ 0.0000e+00,  8.6603e-01,  5.0000e-01,  2.0000e+00],\n",
    "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]])\n",
    "\n",
    "i, j = torch.meshgrid(torch.linspace(0, W-1, W), torch.linspace(0, H-1, H))\n",
    "i = i.t()\n",
    "j = j.t()\n",
    "K = np.array([\n",
    "            [focal, 0, 0.5*W],\n",
    "            [0, focal, 0.5*H],\n",
    "            [0, 0, 1]\n",
    "        ])\n",
    "# K * (x, y, z).T\n",
    "# x * fx / z + 0.5 * W\n",
    "# y * fy / z + 0.5 * H\n",
    "\n",
    "# dirs:\n",
    "# x0 = 0.5 * W, y0 = 0.5 * H\n",
    "# ((i - x0) / fx, (j - y0) / fy, -1).T\n",
    "\n",
    "dirs = torch.stack([(i-K[0][2])/K[0][0], -(j-K[1][2])/K[1][1], -torch.ones_like(i)], -1)\n",
    "print(dirs.shape)\n",
    "print(dirs[0, 0])\n",
    "# # Rotate ray directions from camera frame to the world frame\n",
    "rays_d = torch.sum(dirs[..., np.newaxis, :] * c2w[:3,:3], -1)  # dot product, equals to: [c2w.dot(dir) for dir in dirs]\n",
    "# # Translate camera frame's origin to the world frame. It is the origin of all rays.\n",
    "rays_o = c2w[:3,-1].expand(rays_d.shape)\n",
    "\n",
    "print(rays_d.shape)\n",
    "print(rays_o.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([400, 64, 3])\n"
     ]
    }
   ],
   "source": [
    "H = 400\n",
    "W = 400\n",
    "focal = 555.5555155968841\n",
    "c2w = torch.as_tensor([[1.0000e+00,  6.1232e-17, -1.0606e-16, -4.2423e-16],\n",
    "        [-1.2246e-16,  5.0000e-01, -8.6603e-01, -3.4641e+00],\n",
    "        [ 0.0000e+00,  8.6603e-01,  5.0000e-01,  2.0000e+00],\n",
    "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]])\n",
    "i, j = torch.meshgrid(torch.linspace(0, W-1, W), torch.linspace(0, H-1, H))\n",
    "i = i.t()\n",
    "j = j.t()\n",
    "K = np.array([\n",
    "            [focal, 0, 0.5*W],\n",
    "            [0, focal, 0.5*H],\n",
    "            [0, 0, 1]\n",
    "        ])\n",
    "dirs = torch.stack([(i-K[0][2])/K[0][0], -(j-K[1][2])/K[1][1], -torch.ones_like(i)], -1)\n",
    "rays_d = torch.sum(dirs[..., np.newaxis, :] * c2w[:3,:3], -1) \n",
    "rays_o = c2w[:3,-1].expand(rays_d.shape)\n",
    "\n",
    "near = 2.\n",
    "far = 6.\n",
    "lindisp = True\n",
    "\n",
    "rays_d = rays_d[0]\n",
    "rays_o = rays_o[0]\n",
    "\n",
    "N_samples = 64\n",
    "N_rays = rays_d.shape[0]\n",
    "near, far = near * torch.ones_like(rays_d[...,:1]), far * torch.ones_like(rays_d[...,:1])\n",
    "\n",
    "near = torch.reshape(near, [-1, 1])\n",
    "far = torch.reshape(far, [-1, 1])\n",
    "t_vals = torch.linspace(0., 1., steps=N_samples)\n",
    "\n",
    "if not lindisp:\n",
    "    z_vals = near * (1.-t_vals) + far * (t_vals)\n",
    "else:\n",
    "    z_vals = 1./(1./near * (1.-t_vals) + 1./far * (t_vals))\n",
    "\n",
    "z_vals = z_vals.expand([N_rays, N_samples])\n",
    "\n",
    "pts = rays_o[...,None,:] + rays_d[...,None,:] * z_vals[...,:,None] # [N_rays, N_samples, 3]\n",
    "\n",
    "print(pts.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400, 400, 64, 3)\n",
      "[30.34331236 30.33194737 30.34242353 30.34109415 30.34874571 30.33166636\n",
      " 30.36048589]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "img2mse = lambda x, y : torch.mean((x - y) ** 2)\n",
    "mse2psnr = lambda x : -10. * torch.log(x) / torch.log(torch.Tensor([10.]))\n",
    "to8b = lambda x : (255*np.clip(x,0,1)).astype(np.uint8)\n",
    "\n",
    "def rgb2psnr(x, y):\n",
    "    mse = np.mean((x-y)**2, axis=(0, 1, 3))\n",
    "    psnr = 20 * np.log10(255) - 10 * np.log10(mse)\n",
    "    return psnr\n",
    "\n",
    "a = torch.randn((400, 400, 64, 3)).numpy()\n",
    "b = torch.randn((400, 400, 64, 3)).numpy()\n",
    "print(a.shape)\n",
    "a = to8b(a)\n",
    "b = to8b(b)\n",
    "c = rgb2psnr(a, b)\n",
    "N_samples = 64\n",
    "print(c[list(range(0, N_samples, 10))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19851/1822223169.py:4: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning dissapear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  png = imageio.imread(path)\n"
     ]
    }
   ],
   "source": [
    "import imageio\n",
    "\n",
    "def get_patch(path, savepath):\n",
    "    png = imageio.imread(path)\n",
    "    imageio.imsave(savepath, png[70:200, 120:280])\n",
    "    \n",
    "path1 = 'logs/blender_paper_lego_pose_0_func1/renderonly_path_200000/054.png'\n",
    "savepath1 = 'img1.png'\n",
    "get_patch(path1, savepath1)\n",
    "\n",
    "path2 = 'logs/blender_paper_lego_pose_0_func1/renderonly_path_200000/018.png'\n",
    "savepath2 = 'img2.png'\n",
    "get_patch(path2, savepath2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- sample 18:\n",
    "![](img2.png)\n",
    "- sample 54:\n",
    "![](img1.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
